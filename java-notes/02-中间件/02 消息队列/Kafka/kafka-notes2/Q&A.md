# 一、运行&环境
## 1.云服务器部署kafka，客户机通过API无法调用kafka
由于云主机公网IP与其真实网卡IP并非同一IP，server.properties中配置的监听ip为网卡IP，客户机通过API访问的IP为公网IP，两者不一致，无法监听到。同时这样的访问场景也无实际业务意义。
## 2.本地虚拟机部署kafka，实体机无法调用虚拟机kafka
检查虚拟机防火墙，关闭防火墙重试
```$shell
#查看状态
firewall-cmd --state
#关闭服务
systemctl stop firewalld.service
#禁止开机启动
systemctl disable firewalld.service
```
## 3.主机休眠或睡眠再唤醒，无法连接虚拟机（kafka所在的虚拟机）
原因是休眠后虚拟网卡没有被唤醒，需要在“网络和 Internet\更改适配器选项”找到虚拟网卡，禁用-启用即可

# 二、灵魂拷问
## 消息在kafka中存多久
broker的log.cleanup.policy=delete\compact决定删除还是压缩，可同时支持两种   
log.retention.hours \ log.retention.minutes \ log.retention.ms 时间单位越小，优先级越高   
log.retention.hours默认168，即7天之后就删除或压缩了

## 集群环境，启停kafka节点，分区分配的变化
集群中如果有broker宕机或停止服务，该broker承担的leader分区，将转至其他broker节点负载。再重启该broker后，其不会自动恢复原始的分配   
如果auto.leader.rebalance.enable=true（默认值true），则在leader.imbalance.check.interval.seconds（默认300s）的检查频度后，重新进行分区的再分配   
如果auto.leader.rebalance.enable=false，则服务端不会自动重分配，需要手动通过kafka-leader-election.sh分配

## Kafka的用途有哪些？使用场景如何？
- kafka具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性、消息持久化、流式处理类库等功能、特性     
- 可作为消息系统、存储系统、流处理平台使用   

## Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么
- ISR是所有活着的、在同步数据的replica，即in-sync replica，AR是所有的副本，即assigned replica   
- ISR伸缩理解是同步的副本集合，由于新增、下线、超时等原因产生ISR集合中replica的增减变化，由控制器通知各节点更新元数据，进行相应的新增、剔除、重分配等处理

## Kafka中的HW、LEO、LSO、LW等分别代表什么？
- LSO & LEO，日志起始的offset；日志末尾的offset，下条消息对应的offset
- HW高水位，所有同步消息的副本（ISR）里最慢的副本的offset   
- LW低水位，所有副本（AR）里起始日志最小的offset

## 4.Kafka中是怎么体现消息顺序性的？
只能保证分区内的消息是顺序的，通过递增的offset标识顺序的消息

## Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？
- 拦截器可以有多个自定义的拦截器组成拦截链，在消息序列化前修改消息；序列化器将消息转为二进制数组，用于传输；分区器处理消息应该发往那个分区，分区算法也可自定义
- 拦截器->序列化器->分区器

## Kafka生产者客户端的整体结构是什么样子的？
主线程、sender线程，前者组织消息，后者发送消息   
主线程包括拦截器->序列化器->分区器->消息累加器，构建消息对象、消息累加后传递给sender线程，sender负责发送和接收响应

## Kafka生产者客户端中使用了几个线程来处理？分别是什么？
主线程、sender线程，前者组织消息，后者发送消息

## Kafka的旧版Scala的消费者客户端的设计有什么缺陷？
由于没有消费者协调器和组协调器，每个消费者直接对zookeeper关键节点进行监听，进行再均衡时所有消费者同时进行且互不知晓，导致kafka工作在一个不确定的状态   
同时由于依赖zookeeper集群，还会导致羊群效应（一个节点变化，大量通知发送到客户端，导致消息延迟）和脑裂问题（每个消费者和zookeeper通信，由于zookeeper特性，同一时刻获取的状态不一致）

## “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果正确，那么有没有什么hack的手段？
个人理解描述正确，hack手段是通过客户端partition.assignment.strategy设置消费者与主题之间分区分配策略（如StickyAssignor），让消费者尽可能平均的分配分区，避免有的过载，有的无分区可消费

## 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?
offset+1，消费者提交的offset为下一次拉取的起点

## 有哪些情形会造成重复消费？
- 再平衡时，分区被更换消费者后，在原消费组的状态会丢失，可能导致重复消费
- 正常拉取时，先处理消息，再提交offset，如提交offset时宕机，重启后，会再次拉取已处理过的消息，造成重复消费
- 异步方法在某次执行出错后，可采用重试机制时，重试程序可能将后续提交的偏移量改小，导致重复消费

## 那些情景下会造成消息漏消费？
- 拉取时，先提交offset，再处理消息，那么在处理消息时宕机了，重启后，不会再次拉取已同步offset的消息，造成消息遗漏

## 简述消费者与消费组之间的关系
消费组是一个逻辑概念，消费组下有一个或多个消费者，消费者则隶属一个消费组

## 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？
- 创建：在log.dir目录创建topic目录，并创建与副本等同数量的日志文件及索引文件；同时在zookeeper中创建主题节点，记录topic分区副本信息
- 删除：删除的本质是zookeeper中/admin/delete_topics/下创建了一个待删除节点，由kafka控制器读取节点最终完成主题删除

## topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？
可以增加，通过--kafka-topics.sh + --alter + --partitions N 设置分区需要增加到N个   

## topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？
不可以减少，减少后原分区未处理的消息无法处理

## Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？
- __consumer_offsets：用户消费位移持久化
- __transaction_stat：存储事务消息
- 特征：双下划线开头，不能被删除

## 优先副本是什么？它有什么特殊的作用？
当分区有多个副本，其副本列表中首个副本编号对应为优先副本，通常优先副本即该分区的leader副本   
初始创建状态，分区相对均匀的分布在不同broker，当有broker宕机或下线，宕机节点的leader转至其他broker，会打破均匀状态      
待broker重新上线，一定时间后，会触发重分配，leader节点会重分配为优先节点

## Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理
- 生产者端：分区分配给新产生的消息分配目标分区，可能是随机、通过key或自定义
- 消费者端：分区分配指消费组下的消费者分配各自需要消费的分区，消费者数量变化会再平衡，重新分配
- 主题端：分区分配通过优先副本或人工指定方案的机制，分配分区在各节点的副本分布情况

## 简述Kafka的日志目录结构
在log.dir下，每个主题的一个分区，对应一个文件夹，其下有多个分段的日志文件，即每个副本都有一个组日志文件    

## Kafka中有那些索引文件？
位移索引文件0000000000000000000.index      
时间戳索引文件0000000000000000000.timeindex

## 如果我指定了一个offset，Kafka怎么查找到对应的消息？
- 根据offset与分片的baseOffset比较找到日志所在分片
- offset - baseOffset = 目标相对偏移量，在索引中找到索引中相对偏移量不大于目标偏移量的最大值（因为索引是稀疏索引）
- 获取最大值对应的物理地址，到日志分片从该物理地址开始逐个向后寻找，直至找到目标offset

## 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？
- 用目标时间戳与各个日志分段的最大时间戳进行比较，找到不小于目标时间戳的日志分片
- 在日志分片对应的时间戳索引文件中，二分法查找不大于目标时间的最大时间戳记录
- 拿到记录对应的相对偏移量，到偏移量索引文件中，找到不大于该偏移量的最大偏移量记录
- 拿着该记录的物理地址在日志文件中找到不小于目标时间戳的记录

## 聊一聊你对Kafka的Log Retention的理解
日志清除正常包括两类：   
- 基于设置的retention时间，对超过时间的日志进行清除，默认7天
- 基于设置的retention大小，对于超过大小的日志进行清除，默认1G   
另一种基于偏移量的清除：
- 当执行kafka-record-delete.sh脚本修改logStartOffset时，对于日志分片的下一分片，如果BaseOffset仍小于logStartOffset，则删除该分片（不是删下一分片）

## 聊一聊你对Kafka的Log Compaction的理解
日志压缩不是真正的空间压缩，而是清除掉key相同的消息，只保留一条，剩余数据的offset不变，但重新组合日志分段，故key不可为null

## 聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）
- 页缓存：合理的利用操作系统的页缓存，提高数据访问的性能   
页缓存是操作系统中，对于磁盘访问的缓存，将磁盘数据缓存在内存中，提高访问速度。访问时先查看页缓存中是否存在数据，不存在从磁盘加载到页缓存中再返回
内核层、块层、设备层？？

## 聊一聊Kafka的延时操作的原理
- 由于kafka的工作机制，很多行为无法实时、同步返回结果，需要异步操作处理结果   
- 如由于消息的冗余存储，生产者生产消息后，leader节点收到消息，follower节点需要完成拉取同步，才视为消息生产完毕（ack=-1时），才返回响应，所以要有个延时的处理   
延时有两个要素，一个有事件驱动，如“生产消息同步完”这一事件驱动；另一个是截止时间点，如果外部时间驱动迟迟未到，或超过一定时间，则延迟操作会自动开始   

## 聊一聊Kafka控制器的作用


## 消费再均衡的原理是什么
- 消费者客户端有消费者协调器，kafka服务端有消费组协调器，两者交互作用进行再均衡
- 消费者会给组协调器发心跳，当有消费者死亡，触发再均衡。再均衡由消费者协调器连接消费组协调器，选出该消费组的leader，leader负责收集各消费者支持的再均衡策略，组织投票选择策略，再将结果组内同步。完成同步后，再建立心跳和心跳监控，如又有新增、死亡的消费者或订阅topic的变化，再进行重分配

## Kafka中的幂等是怎么实现的
## Kafka中的事务是怎么实现的
## Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？
## 失效副本是指什么？有那些应对措施？
## 多副本下，各个副本中的HW和LEO的演变过程
## 为什么Kafka不支持读写分离？
## Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）
## Kafka中怎么实现死信队列和重试队列？
## Kafka中的延迟队列怎么实现
## Kafka中怎么做消息审计？
## Kafka中怎么做消息轨迹？
## Kafka中有那些配置参数比较有意思？聊一聊你的看法
## Kafka中有那些命名比较有意思？聊一聊你的看法
## Kafka有哪些指标需要着重关注？
## 怎么计算Lag？
## Kafka的那些设计让它有如此高的性能？
## Kafka有什么优缺点？
## 还用过什么同质类的其它产品，与Kafka相比有什么优缺点？
## 为什么选择Kafka?
## 在使用Kafka的过程中遇到过什么困难？怎么解决的？
## 怎么样才能确保Kafka极大程度上的可靠性？
## 聊一聊你对Kafka生态的理解
## KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？
## 创建topic时如何选择合适的分区数？
